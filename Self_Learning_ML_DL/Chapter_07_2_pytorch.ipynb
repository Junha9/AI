{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCAElsePeCdA4KjvlOw/Wk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junha9/AI/blob/master/Self_Learning_ML_DL/Chapter_07_2_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BAJFvUnyMEVz"
      },
      "outputs": [],
      "source": [
        "# import statements\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the FashionMNIST data\n",
        "fm_train = FashionMNIST(root='.', train=True, download=True)\n",
        "fm_test = FashionMNIST(root='.', train=False, download=True)"
      ],
      "metadata": {
        "id": "PvVgb-jiMNca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829b0308-0056-474e-d735-bcbc8a0c3ec5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.81MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 29.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dataset. It is composed of torch.Tensor class.\n",
        "print(type(fm_train.data))\n",
        "print(fm_train.data.shape, fm_test.data.shape)\n",
        "print(fm_train.targets.shape, fm_test.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IptWCXFHMcIX",
        "outputId": "272b9dd7-fda8-47ce-eaa9-c1183a86f582"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
            "torch.Size([60000]) torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch tensor also supports broadcasting just like numpy array.\n",
        "train_input = fm_train.data\n",
        "train_target = fm_train.targets\n",
        "train_scaled = train_input / 255.0"
      ],
      "metadata": {
        "id": "Vsm_qDKQMmKW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "print(train_scaled.shape, val_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dApzKHgmNTEl",
        "outputId": "23db317d-a097-4231-ea8b-9dd561080533"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([48000, 28, 28]) torch.Size([12000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100,10)\n",
        ")"
      ],
      "metadata": {
        "id": "r2B1fNlvmJ4D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(32, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4lqgCyU0kN6",
        "outputId": "c8974837-0105-4d73-f709-e2b31aba59de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [32, 10]                  --\n",
              "├─Flatten: 1-1                           [32, 784]                 --\n",
              "├─Linear: 1-2                            [32, 100]                 78,500\n",
              "├─ReLU: 1-3                              [32, 100]                 --\n",
              "├─Linear: 1-4                            [32, 10]                  1,010\n",
              "==========================================================================================\n",
              "Total params: 79,510\n",
              "Trainable params: 79,510\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 2.54\n",
              "==========================================================================================\n",
              "Input size (MB): 0.10\n",
              "Forward/backward pass size (MB): 0.03\n",
              "Params size (MB): 0.32\n",
              "Estimated Total Size (MB): 0.45\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCeWNLh_5UrR",
        "outputId": "0d0fa3b2-35fa-489e-8900-7bf13b6b2446"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "kvUxTkaHAqsU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to manually train the model when using pytorch\n",
        "epochs = 5\n",
        "batches = int(len(train_scaled)/32)\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  for i in range(batches):\n",
        "    inputs = train_scaled[i*32:(i+1)*32].to(device)\n",
        "    targets = train_target[i*32:(i+1)*32].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  print(f\"epoch: {epoch + 1}, loss: {train_loss/batches:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgniRXNsA2wu",
        "outputId": "65ef5a77-fd3e-4433-d157-06c6db1e6214"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 0.5435\n",
            "epoch: 2, loss: 0.4022\n",
            "epoch: 3, loss: 0.3613\n",
            "epoch: 4, loss: 0.3341\n",
            "epoch: 5, loss: 0.3127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We also have to manually evaluate when using pytorch\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  val_scaled = val_scaled.to(device)\n",
        "  val_target = val_target.to(device)\n",
        "  outputs = model(val_scaled)\n",
        "  predicts = torch.argmax(outputs, 1)\n",
        "  corrects = (predicts == val_target).sum().item()\n",
        "accuracy = corrects / len(val_target)\n",
        "print(f\"accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RoQB9gYCM3S",
        "outputId": "3c041050-90ee-4787-b867-925c33e041de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8705\n"
          ]
        }
      ]
    }
  ]
}